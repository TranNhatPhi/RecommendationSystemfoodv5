import openai
import json
import requests
from typing import Dict, List, Optional
import pandas as pd
from simple_food_db import SimpleFoodRecommendationDB
import os
from datetime import datetime

# Import cache manager
try:
    from cache_manager import cached, cache_manager
    CACHING_ENABLED = True
except ImportError:
    CACHING_ENABLED = False
    print("‚ö†Ô∏è Cache manager not available - running without caching")

    # Fallback decorator
    def cached(expire_hours: int = 24):
        def decorator(func):
            return func
        return decorator


class FoodAIAgent:
    def __init__(self, openai_api_key: str = None):
        """Initialize the Food AI Agent with OpenAI integration"""
        # Set OpenAI API key (you should set this as environment variable)
        if openai_api_key:
            openai.api_key = openai_api_key
        elif os.getenv('OPENAI_API_KEY'):
            openai.api_key = os.getenv('OPENAI_API_KEY')
        else:
            print("‚ö†Ô∏è Warning: OpenAI API key not provided. Some features may not work.")
          # Initialize simple database
        self.vector_db = SimpleFoodRecommendationDB()

        # Professional prompt for the AI agent
        self.system_prompt = """
        B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n ·∫©m th·ª±c v√† dinh d∆∞·ª°ng chuy√™n nghi·ªáp, c√≥ nhi·ªám v·ª• ƒë∆∞a ra c√°c g·ª£i √Ω m√≥n ƒÉn an to√†n, h·ª£p v·ªá sinh, ph√π h·ª£p v·ªõi t·ª´ng nh√≥m ng∆∞·ªùi d√πng. 

        M·ª§C TI√äU CH√çNH:
        - Gi√∫p ng∆∞·ªùi ti√™u d√πng l·ª±a ch·ªçn th·ª±c ƒë∆°n v·ª´a ngon mi·ªáng, v·ª´a ƒë·∫£m b·∫£o s·ª©c kh·ªèe
        - ∆Øu ti√™n an to√†n th·ª±c ph·∫©m v√† v·ªá sinh dinh d∆∞·ª°ng
        - T∆∞ v·∫•n ph√π h·ª£p v·ªõi t·ª´ng nh√≥m ƒë·ªëi t∆∞·ª£ng (tr·∫ª em, ng∆∞·ªùi gi√†, ng∆∞·ªùi b·ªánh, v.v.)
        - ƒê∆∞a ra gi·∫£i ph√°p th·ª±c t·∫ø, s√°ng t·∫°o v√† d·ªÖ th·ª±c hi·ªán

        PHONG C√ÅCH T∆Ø V·∫§N:
        - Th√¢n thi·ªán, nhi·ªát t√¨nh v√† d·ªÖ hi·ªÉu
        - D·ª±a tr√™n d·ªØ li·ªáu v√† nghi√™n c·ª©u khoa h·ªçc
        - Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ dinh d∆∞·ª°ng
        - ƒê∆∞a ra l·ª±a ch·ªçn thay th·∫ø khi c·∫ßn thi·∫øt

        Lƒ®NH V·ª∞C CHUY√äN M√îN:
        - M√≥n ƒÉn Vi·ªát Nam truy·ªÅn th·ªëng v√† hi·ªán ƒë·∫°i
        - Dinh d∆∞·ª°ng cho c√°c nh√≥m tu·ªïi kh√°c nhau
        - An to√†n th·ª±c ph·∫©m v√† v·ªá sinh
        - Ch·∫ø ƒë·ªô ƒÉn ƒë·∫∑c bi·ªát (gi·∫£m c√¢n, ti·ªÉu ƒë∆∞·ªùng, tim m·∫°ch, v.v.)        - M√≥n ƒÉn ph√π h·ª£p v·ªõi ƒëi·ªÅu ki·ªán ƒë·ªãa ph∆∞∆°ng

        H√£y lu√¥n ƒë∆∞a ra l·ªùi khuy√™n c√≥ cƒÉn c·ª© v√† th·ª±c t·∫ø, ∆∞u ti√™n s·ª©c kh·ªèe c·ªßa ng∆∞·ªùi d√πng.
        """

    @cached(expire_hours=2)  # Cache for 2 hours
    def get_contextual_data(self, user_query: str, user_id: str = None) -> Dict:
        """Get relevant contextual data from vector database"""
        context_data = {
            "recipes": [],
            "customer_info": {},
            "recommendations": []
        }

        try:
            # Search for relevant recipes
            recipe_results = self.vector_db.search_recipes(
                user_query, n_results=8)
            if recipe_results and recipe_results['documents']:
                for i, (doc, meta) in enumerate(zip(recipe_results['documents'][0], recipe_results['metadatas'][0])):
                    context_data["recipes"].append({
                        "name": meta['recipe_name'],
                        "url": meta['recipe_url'],
                        "difficulty": meta['difficulty'],
                        "meal_time": meta['meal_time'],
                        "nutrition_category": meta['nutrition_category'],
                        "calories": meta['estimated_calories'],
                        "prep_time": meta['preparation_time_minutes'],
                        "ingredients": meta['ingredient_count'],
                        "price": meta['estimated_price_vnd'],
                        "rating": meta['avg_rating']
                    })

            # Get customer information if user_id provided
            if user_id:
                customer_results = self.vector_db.search_customers(
                    f"customer_id {user_id}", n_results=1)
                if customer_results and customer_results['metadatas']:
                    context_data["customer_info"] = customer_results['metadatas'][0][0]

        except Exception as e:
            print(f"Error getting contextual data: {str(e)}")

        return context_data

    def get_nearby_restaurants(self, location: str, food_type: str = "") -> List[Dict]:
        """Simulate getting nearby restaurants (Google Maps integration placeholder)"""
        # This is a placeholder for Google Maps API integration
        # In a real implementation, you would use Google Places API
        mock_restaurants = [
            {
                "name": "Qu√°n C∆°m T·∫•m S√†i G√≤n",
                "address": f"123 ƒê∆∞·ªùng ABC, {location}",
                "rating": 4.5,
                "price_range": "50,000 - 100,000 VND",
                "specialties": ["C∆°m t·∫•m", "S∆∞·ªùn n∆∞·ªõng", "Ch·∫£ tr·ª©ng"],
                "distance": "0.5 km",
                "opening_hours": "7:00 - 22:00"
            },
            {
                "name": "Nh√† H√†ng M√≥n Hu·∫ø",
                "address": f"456 ƒê∆∞·ªùng XYZ, {location}",
                "rating": 4.3,
                "price_range": "80,000 - 150,000 VND",
                "specialties": ["B√∫n b√≤ Hu·∫ø", "Nem l·ª•i", "B√°nh kho√°i"],
                "distance": "0.8 km",
                "opening_hours": "8:00 - 21:30"
            },
            {
                "name": "Qu√°n Ph·ªü H√† N·ªôi",
                "address": f"789 ƒê∆∞·ªùng DEF, {location}",
                "rating": 4.7,
                "price_range": "40,000 - 80,000 VND",
                "specialties": ["Ph·ªü b√≤", "Ph·ªü g√†", "B√∫n ch·∫£"],
                "distance": "1.2 km",
                "opening_hours": "6:00 - 23:00"
            }
        ]
        # Filter by food type if specified
        if food_type:
            filtered_restaurants = []
            for restaurant in mock_restaurants:
                if any(food_type.lower() in specialty.lower() for specialty in restaurant['specialties']):
                    filtered_restaurants.append(restaurant)
            return filtered_restaurants if filtered_restaurants else mock_restaurants

        return mock_restaurants

    def generate_ai_response(self, user_query: str, context_data: Dict, user_id: str = None) -> str:
        """Generate AI response using OpenAI API with contextual data"""
        try:
            # Prepare context information
            context_text = ""

            if context_data["recipes"]:
                context_text += "\n\nC√ÅC M√ìN ƒÇN LI√äN QUAN:\n"
                for recipe in context_data["recipes"][:5]:  # Limit to top 5
                    context_text += f"- {recipe['name']}: {recipe['nutrition_category']}, {recipe['difficulty']}, {recipe['calories']} kcal, {recipe['prep_time']} ph√∫t\n"

            if context_data["customer_info"]:
                customer = context_data["customer_info"]
                context_text += f"\n\nTH√îNG TIN KH√ÅCH H√ÄNG:\n"
                context_text += f"- T√™n: {customer.get('full_name', 'N/A')}\n"
                context_text += f"- Nh√≥m tu·ªïi: {customer.get('age_group', 'N/A')}\n"
                context_text += f"- Khu v·ª±c: {customer.get('region', 'N/A')}\n"

            # Create the full prompt
            full_prompt = f"""
            {self.system_prompt}

            TH√îNG TIN NG·ªÆ C·∫¢NH:
            {context_text}

            C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:
            {user_query}

            H√£y ƒë∆∞a ra l·ªùi t∆∞ v·∫•n chi ti·∫øt, th·ª±c t·∫ø v√† h·ªØu √≠ch d·ª±a tr√™n th√¥ng tin ng·ªØ c·∫£nh tr√™n.
            """

            # Call OpenAI API (if available) - Updated for OpenAI v1.0+
            if hasattr(openai, 'api_key') and openai.api_key:
                from openai import OpenAI
                client = OpenAI(api_key=openai.api_key)

                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user",
                            "content": f"{context_text}\n\nC√¢u h·ªèi: {user_query}"}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                return response.choices[0].message.content
            else:
                # Fallback response when OpenAI API is not available
                return self.generate_fallback_response(user_query, context_data)

        except Exception as e:
            print(f"Error generating AI response: {str(e)}")
            return self.generate_fallback_response(user_query, context_data)

    def generate_fallback_response(self, user_query: str, context_data: Dict) -> str:
        """Generate fallback response when OpenAI API is not available"""
        response = "üçΩÔ∏è **T∆∞ v·∫•n m√≥n ƒÉn t·ª´ chuy√™n gia dinh d∆∞·ª°ng**\n\n"

        # Analyze query for key topics
        query_lower = user_query.lower()

        if "s·ª©c kh·ªèe" in query_lower or "dinh d∆∞·ª°ng" in query_lower:
            response += "**V·ªÅ dinh d∆∞·ª°ng v√† s·ª©c kh·ªèe:**\n"
            response += "- ∆Øu ti√™n c√°c m√≥n gi√†u ch·∫•t x∆°, vitamin v√† kho√°ng ch·∫•t\n"
            response += "- H·∫°n ch·∫ø ƒë·ªì chi√™n r√°n, nhi·ªÅu d·∫ßu m·ª°\n"
            response += "- C√¢n b·∫±ng protein, carb v√† ch·∫•t b√©o t·ªët\n\n"

        if "ti·ªÉu ƒë∆∞·ªùng" in query_lower or "ƒë∆∞·ªùng huy·∫øt" in query_lower:
            response += "**D√†nh cho ng∆∞·ªùi ti·ªÉu ƒë∆∞·ªùng:**\n"
            response += "- Ch·ªçn m√≥n √≠t ƒë∆∞·ªùng, √≠t tinh b·ªôt\n"
            response += "- TƒÉng c∆∞·ªùng rau xanh, protein n·∫°c\n"
            response += "- Chia nh·ªè b·ªØa ƒÉn trong ng√†y\n\n"

        if "d·ªÖ l√†m" in query_lower or "d·ªÖ ch·∫ø bi·∫øn" in query_lower:
            response += "**M√≥n ƒÉn d·ªÖ ch·∫ø bi·∫øn:**\n"
            response += "- C√°c m√≥n lu·ªôc, h·∫•p ƒë∆°n gi·∫£n\n"
            response += "- Salad, g·ªèi t∆∞∆°i m√°t\n"
            response += "- Canh chua, soup dinh d∆∞·ª°ng\n\n"

        # Add relevant recipes from context
        if context_data["recipes"]:
            response += "**G·ª£i √Ω m√≥n ƒÉn ph√π h·ª£p:**\n"
            for i, recipe in enumerate(context_data["recipes"][:3], 1):
                response += f"{i}. **{recipe['name']}**\n"
                response += f"   - ƒê·ªô kh√≥: {recipe['difficulty']}\n"
                response += f"   - Th·ªùi gian: {recipe['prep_time']} ph√∫t\n"
                response += f"   - Calories: {recipe['calories']} kcal\n"
                response += f"   - Ph√π h·ª£p: {recipe['nutrition_category']}\n\n"

        # Add customer-specific advice
        if context_data["customer_info"]:
            customer = context_data["customer_info"]
            age_group = customer.get('age_group', '')
            region = customer.get('region', '')

            response += f"**L·ªùi khuy√™n c√° nh√¢n h√≥a:**\n"
            if age_group:
                if "18-24" in age_group:
                    response += "- Ph√π h·ª£p v·ªõi l·ª©a tu·ªïi tr·∫ª: c·∫ßn nhi·ªÅu nƒÉng l∆∞·ª£ng, ƒëa d·∫°ng m√≥n ƒÉn\n"
                elif "65+" in age_group:
                    response += "- Ph√π h·ª£p cho ng∆∞·ªùi cao tu·ªïi: d·ªÖ ti√™u h√≥a, m·ªÅm, b·ªï d∆∞·ª°ng\n"
                else:
                    response += "- C√¢n b·∫±ng dinh d∆∞·ª°ng theo ƒë·ªô tu·ªïi, ch√∫ √Ω s·ª©c kh·ªèe tim m·∫°ch\n"

            if region:
                response += f"- M√≥n ƒÉn ƒë·ªãa ph∆∞∆°ng {region}: t·∫≠n d·ª•ng nguy√™n li·ªáu t∆∞∆°i s·∫µn c√≥\n"

        response += "\nüí° **L·ªùi khuy√™n chung:**\n"
        response += "- Lu√¥n ch·ªçn nguy√™n li·ªáu t∆∞∆°i, s·∫°ch\n"
        response += "- ƒê·∫£m b·∫£o v·ªá sinh an to√†n th·ª±c ph·∫©m\n"
        response += "- C√¢n b·∫±ng c√°c nh√≥m ch·∫•t dinh d∆∞·ª°ng\n"
        response += "- U·ªëng ƒë·ªß n∆∞·ªõc, ƒÉn ƒë√∫ng gi·ªù\n"

        return response

    @cached(expire_hours=1)
    def process_user_request(self, user_query: str, user_id: str = None, location: str = None) -> Dict:
        """Main method to process user request and return comprehensive response"""
        try:
            # Get contextual data from vector database
            context_data = self.get_contextual_data(user_query, user_id)

            # Generate AI response
            ai_response = self.generate_ai_response(
                user_query, context_data, user_id)

            # Get nearby restaurants if location provided
            nearby_restaurants = []
            if location:
                # Extract food type from query for restaurant filtering
                food_keywords = ["ph·ªü", "c∆°m", "b√∫n",
                                 "b√°nh", "ch·∫£", "g·ªèi", "salad"]
                food_type = ""
                for keyword in food_keywords:
                    if keyword in user_query.lower():
                        food_type = keyword
                        break

                nearby_restaurants = self.get_nearby_restaurants(
                    location, food_type)

            return {
                "ai_response": ai_response,
                "recommended_recipes": context_data["recipes"][:5],
                "customer_info": context_data["customer_info"],
                "nearby_restaurants": nearby_restaurants,
                "timestamp": datetime.now().isoformat(),
                "query": user_query
            }

        except Exception as e:
            return {
                "ai_response": f"Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra: {str(e)}. Vui l√≤ng th·ª≠ l·∫°i sau.",
                "recommended_recipes": [],
                "customer_info": {},
                "nearby_restaurants": [],
                "timestamp": datetime.now().isoformat(),
                "query": user_query,
                "error": str(e)
            }

# Utility functions for the Flask app


def get_agent_instance():
    """Get singleton instance of the AI agent"""
    if not hasattr(get_agent_instance, '_instance'):
        get_agent_instance._instance = FoodAIAgent()
    return get_agent_instance._instance
